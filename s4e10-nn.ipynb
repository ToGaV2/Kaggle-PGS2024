{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b46d5ff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-09T01:04:23.959210Z",
     "iopub.status.busy": "2024-11-09T01:04:23.958310Z",
     "iopub.status.idle": "2024-11-09T01:04:42.504971Z",
     "shell.execute_reply": "2024-11-09T01:04:42.503742Z"
    },
    "papermill": {
     "duration": 18.56357,
     "end_time": "2024-11-09T01:04:42.507848",
     "exception": false,
     "start_time": "2024-11-09T01:04:23.944278",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF Version  2.16.1\n",
      "Shapes: (91226, 12) (39098, 11)\n",
      "nans:  person_age                    0\n",
      "person_income                 0\n",
      "person_home_ownership         0\n",
      "person_emp_length             0\n",
      "loan_intent                   0\n",
      "loan_grade                    0\n",
      "loan_amnt                     0\n",
      "loan_int_rate                 0\n",
      "loan_percent_income           0\n",
      "cb_person_default_on_file     0\n",
      "cb_person_cred_hist_length    0\n",
      "loan_status                   0\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(87146, 12)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import libraries\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import log_loss, roc_auc_score\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Input, Embedding\n",
    "from tensorflow.keras.layers import Concatenate, Multiply\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "# check TF and make GPUs available\n",
    "print(\"TF Version \", tf.__version__)\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"0,1,2\"\n",
    "\n",
    "# import the data\n",
    "train = pd.read_csv(\"/kaggle/input/playground-series-s4e10/train.csv\", index_col=\"id\")\n",
    "test = pd.read_csv(\"/kaggle/input/playground-series-s4e10/test.csv\", index_col=\"id\")\n",
    "orig_df = pd.read_csv('/kaggle/input/loan-approval-prediction/credit_risk_dataset.csv')\n",
    "\n",
    "# combine dfs\n",
    "orig_df = orig_df[['person_age', 'person_income', 'person_home_ownership',\n",
    "        'person_emp_length', 'loan_intent', 'loan_grade', 'loan_amnt',\n",
    "        'loan_int_rate', 'loan_percent_income', 'cb_person_default_on_file',\n",
    "        'cb_person_cred_hist_length', 'loan_status']]\n",
    "train = pd.concat([train,orig_df], axis=0)\n",
    "print(\"Shapes:\" , train.shape, test.shape)\n",
    "\n",
    "# drop dupes and nas\n",
    "train = train.dropna()\n",
    "print(\"nans: \", train.isna().sum())\n",
    "\n",
    "train = train.drop_duplicates()\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3b30237",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-09T01:04:42.528731Z",
     "iopub.status.busy": "2024-11-09T01:04:42.527581Z",
     "iopub.status.idle": "2024-11-09T01:04:42.565977Z",
     "shell.execute_reply": "2024-11-09T01:04:42.564790Z"
    },
    "papermill": {
     "duration": 0.051961,
     "end_time": "2024-11-09T01:04:42.569089",
     "exception": false,
     "start_time": "2024-11-09T01:04:42.517128",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = train.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "109fcccf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-09T01:04:42.588201Z",
     "iopub.status.busy": "2024-11-09T01:04:42.587745Z",
     "iopub.status.idle": "2024-11-09T01:04:42.644474Z",
     "shell.execute_reply": "2024-11-09T01:04:42.642989Z"
    },
    "papermill": {
     "duration": 0.069797,
     "end_time": "2024-11-09T01:04:42.647395",
     "exception": false,
     "start_time": "2024-11-09T01:04:42.577598",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define a high risk flag\n",
    "train['riskflag'] = 0\n",
    "train.loc[(train['cb_person_default_on_file']==\"Y\")&(train['loan_grade'].isin(['C','D','E','F','G'])),'riskflag'] = 1\n",
    "test['riskflag'] = 0\n",
    "test.loc[(test['cb_person_default_on_file']==\"Y\")&(test['loan_grade'].isin(['C','D','E','F','G'])),'riskflag'] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9dc95716",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-09T01:04:42.666715Z",
     "iopub.status.busy": "2024-11-09T01:04:42.666205Z",
     "iopub.status.idle": "2024-11-09T01:04:42.683336Z",
     "shell.execute_reply": "2024-11-09T01:04:42.682227Z"
    },
    "papermill": {
     "duration": 0.030355,
     "end_time": "2024-11-09T01:04:42.686394",
     "exception": false,
     "start_time": "2024-11-09T01:04:42.656039",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# loan to income ratio\n",
    "train['loanincomeratio']= train['loan_amnt']/train['person_income'] - train['loan_percent_income']\n",
    "test['loanincomeratio']= test['loan_amnt']/test['person_income'] - test['loan_percent_income']\n",
    "# loan to employment length ratio\n",
    "train['loanemploymentratio']= train['loan_amnt']/(train['person_emp_length'] + .0001)  \n",
    "test['loanemploymentratio']= test['loan_amnt']/(test['person_emp_length']  + .0001)\n",
    "# interaction (age * income)\n",
    "train['intageincome']= train['person_age'] * train['person_income']  \n",
    "test['intageincome']= test['person_age'] * test['person_income']  \n",
    "# monthly income\n",
    "train['monthlyincome']=  train['person_income'] /12\n",
    "test['monthlyincome']=  test['person_income'] /12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a2ca9084",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-09T01:04:42.706169Z",
     "iopub.status.busy": "2024-11-09T01:04:42.705724Z",
     "iopub.status.idle": "2024-11-09T01:04:42.742448Z",
     "shell.execute_reply": "2024-11-09T01:04:42.741267Z"
    },
    "papermill": {
     "duration": 0.049783,
     "end_time": "2024-11-09T01:04:42.745504",
     "exception": false,
     "start_time": "2024-11-09T01:04:42.695721",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person_age</th>\n",
       "      <th>person_income</th>\n",
       "      <th>person_home_ownership</th>\n",
       "      <th>person_emp_length</th>\n",
       "      <th>loan_intent</th>\n",
       "      <th>loan_grade</th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>loan_int_rate</th>\n",
       "      <th>loan_percent_income</th>\n",
       "      <th>cb_person_default_on_file</th>\n",
       "      <th>cb_person_cred_hist_length</th>\n",
       "      <th>loan_status</th>\n",
       "      <th>riskflag</th>\n",
       "      <th>loanincomeratio</th>\n",
       "      <th>loanemploymentratio</th>\n",
       "      <th>intageincome</th>\n",
       "      <th>monthlyincome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37</td>\n",
       "      <td>35000</td>\n",
       "      <td>RENT</td>\n",
       "      <td>0.0</td>\n",
       "      <td>EDUCATION</td>\n",
       "      <td>B</td>\n",
       "      <td>6000</td>\n",
       "      <td>11.49</td>\n",
       "      <td>0.17</td>\n",
       "      <td>N</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001429</td>\n",
       "      <td>6.000000e+07</td>\n",
       "      <td>1295000</td>\n",
       "      <td>2916.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22</td>\n",
       "      <td>56000</td>\n",
       "      <td>OWN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>MEDICAL</td>\n",
       "      <td>C</td>\n",
       "      <td>4000</td>\n",
       "      <td>13.35</td>\n",
       "      <td>0.07</td>\n",
       "      <td>N</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001429</td>\n",
       "      <td>6.666556e+02</td>\n",
       "      <td>1232000</td>\n",
       "      <td>4666.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29</td>\n",
       "      <td>28800</td>\n",
       "      <td>OWN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>PERSONAL</td>\n",
       "      <td>A</td>\n",
       "      <td>6000</td>\n",
       "      <td>8.90</td>\n",
       "      <td>0.21</td>\n",
       "      <td>N</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.001667</td>\n",
       "      <td>7.499906e+02</td>\n",
       "      <td>835200</td>\n",
       "      <td>2400.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30</td>\n",
       "      <td>70000</td>\n",
       "      <td>RENT</td>\n",
       "      <td>14.0</td>\n",
       "      <td>VENTURE</td>\n",
       "      <td>B</td>\n",
       "      <td>12000</td>\n",
       "      <td>11.11</td>\n",
       "      <td>0.17</td>\n",
       "      <td>N</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001429</td>\n",
       "      <td>8.571367e+02</td>\n",
       "      <td>2100000</td>\n",
       "      <td>5833.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22</td>\n",
       "      <td>60000</td>\n",
       "      <td>RENT</td>\n",
       "      <td>2.0</td>\n",
       "      <td>MEDICAL</td>\n",
       "      <td>A</td>\n",
       "      <td>6000</td>\n",
       "      <td>6.92</td>\n",
       "      <td>0.10</td>\n",
       "      <td>N</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.999850e+03</td>\n",
       "      <td>1320000</td>\n",
       "      <td>5000.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   person_age  person_income person_home_ownership  person_emp_length  \\\n",
       "0          37          35000                  RENT                0.0   \n",
       "1          22          56000                   OWN                6.0   \n",
       "2          29          28800                   OWN                8.0   \n",
       "3          30          70000                  RENT               14.0   \n",
       "4          22          60000                  RENT                2.0   \n",
       "\n",
       "  loan_intent loan_grade  loan_amnt  loan_int_rate  loan_percent_income  \\\n",
       "0   EDUCATION          B       6000          11.49                 0.17   \n",
       "1     MEDICAL          C       4000          13.35                 0.07   \n",
       "2    PERSONAL          A       6000           8.90                 0.21   \n",
       "3     VENTURE          B      12000          11.11                 0.17   \n",
       "4     MEDICAL          A       6000           6.92                 0.10   \n",
       "\n",
       "  cb_person_default_on_file  cb_person_cred_hist_length  loan_status  \\\n",
       "0                         N                          14            0   \n",
       "1                         N                           2            0   \n",
       "2                         N                          10            0   \n",
       "3                         N                           5            0   \n",
       "4                         N                           3            0   \n",
       "\n",
       "   riskflag  loanincomeratio  loanemploymentratio  intageincome  monthlyincome  \n",
       "0         0         0.001429         6.000000e+07       1295000    2916.666667  \n",
       "1         0         0.001429         6.666556e+02       1232000    4666.666667  \n",
       "2         0        -0.001667         7.499906e+02        835200    2400.000000  \n",
       "3         0         0.001429         8.571367e+02       2100000    5833.333333  \n",
       "4         0         0.000000         2.999850e+03       1320000    5000.000000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = train.drop(columns=['index'])\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e97e507",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-09T01:04:42.766196Z",
     "iopub.status.busy": "2024-11-09T01:04:42.765729Z",
     "iopub.status.idle": "2024-11-09T01:04:42.875849Z",
     "shell.execute_reply": "2024-11-09T01:04:42.874593Z"
    },
    "papermill": {
     "duration": 0.123611,
     "end_time": "2024-11-09T01:04:42.878815",
     "exception": false,
     "start_time": "2024-11-09T01:04:42.755204",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person_age</th>\n",
       "      <th>person_income</th>\n",
       "      <th>person_emp_length</th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>loan_int_rate</th>\n",
       "      <th>loan_percent_income</th>\n",
       "      <th>cb_person_cred_hist_length</th>\n",
       "      <th>loan_status</th>\n",
       "      <th>riskflag</th>\n",
       "      <th>loanincomeratio</th>\n",
       "      <th>loanemploymentratio</th>\n",
       "      <th>intageincome</th>\n",
       "      <th>monthlyincome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>87146.000000</td>\n",
       "      <td>8.714600e+04</td>\n",
       "      <td>87146.000000</td>\n",
       "      <td>87146.000000</td>\n",
       "      <td>87146.000000</td>\n",
       "      <td>87146.000000</td>\n",
       "      <td>87146.000000</td>\n",
       "      <td>87146.000000</td>\n",
       "      <td>87146.000000</td>\n",
       "      <td>87146.000000</td>\n",
       "      <td>8.714600e+04</td>\n",
       "      <td>8.714600e+04</td>\n",
       "      <td>87146.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>27.612283</td>\n",
       "      <td>6.489919e+04</td>\n",
       "      <td>4.730165</td>\n",
       "      <td>9361.777385</td>\n",
       "      <td>10.798068</td>\n",
       "      <td>0.162599</td>\n",
       "      <td>5.809286</td>\n",
       "      <td>0.166823</td>\n",
       "      <td>0.158148</td>\n",
       "      <td>0.000478</td>\n",
       "      <td>1.101670e+07</td>\n",
       "      <td>1.830919e+06</td>\n",
       "      <td>5408.266190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6.127790</td>\n",
       "      <td>4.735139e+04</td>\n",
       "      <td>4.025696</td>\n",
       "      <td>5828.985176</td>\n",
       "      <td>3.104952</td>\n",
       "      <td>0.096872</td>\n",
       "      <td>4.033420</td>\n",
       "      <td>0.372820</td>\n",
       "      <td>0.364882</td>\n",
       "      <td>0.019174</td>\n",
       "      <td>3.473220e+07</td>\n",
       "      <td>3.286459e+06</td>\n",
       "      <td>3945.949487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>20.000000</td>\n",
       "      <td>4.000000e+03</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>5.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.535290</td>\n",
       "      <td>4.761882e+01</td>\n",
       "      <td>8.568000e+04</td>\n",
       "      <td>333.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>23.000000</td>\n",
       "      <td>4.000000e+04</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>7.880000</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.002500</td>\n",
       "      <td>1.070965e+03</td>\n",
       "      <td>1.075000e+06</td>\n",
       "      <td>3333.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>26.000000</td>\n",
       "      <td>5.700000e+04</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>10.990000</td>\n",
       "      <td>0.140000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.142827e+03</td>\n",
       "      <td>1.512000e+06</td>\n",
       "      <td>4750.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>30.000000</td>\n",
       "      <td>7.800000e+04</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>12000.000000</td>\n",
       "      <td>13.110000</td>\n",
       "      <td>0.220000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002506</td>\n",
       "      <td>4.999833e+03</td>\n",
       "      <td>2.175000e+06</td>\n",
       "      <td>6500.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>144.000000</td>\n",
       "      <td>6.000000e+06</td>\n",
       "      <td>123.000000</td>\n",
       "      <td>35000.000000</td>\n",
       "      <td>23.220000</td>\n",
       "      <td>0.830000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.815000</td>\n",
       "      <td>3.500000e+08</td>\n",
       "      <td>8.640000e+08</td>\n",
       "      <td>500000.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         person_age  person_income  person_emp_length     loan_amnt  \\\n",
       "count  87146.000000   8.714600e+04       87146.000000  87146.000000   \n",
       "mean      27.612283   6.489919e+04           4.730165   9361.777385   \n",
       "std        6.127790   4.735139e+04           4.025696   5828.985176   \n",
       "min       20.000000   4.000000e+03           0.000000    500.000000   \n",
       "25%       23.000000   4.000000e+04           2.000000   5000.000000   \n",
       "50%       26.000000   5.700000e+04           4.000000   8000.000000   \n",
       "75%       30.000000   7.800000e+04           7.000000  12000.000000   \n",
       "max      144.000000   6.000000e+06         123.000000  35000.000000   \n",
       "\n",
       "       loan_int_rate  loan_percent_income  cb_person_cred_hist_length  \\\n",
       "count   87146.000000         87146.000000                87146.000000   \n",
       "mean       10.798068             0.162599                    5.809286   \n",
       "std         3.104952             0.096872                    4.033420   \n",
       "min         5.420000             0.000000                    2.000000   \n",
       "25%         7.880000             0.090000                    3.000000   \n",
       "50%        10.990000             0.140000                    4.000000   \n",
       "75%        13.110000             0.220000                    8.000000   \n",
       "max        23.220000             0.830000                   30.000000   \n",
       "\n",
       "        loan_status      riskflag  loanincomeratio  loanemploymentratio  \\\n",
       "count  87146.000000  87146.000000     87146.000000         8.714600e+04   \n",
       "mean       0.166823      0.158148         0.000478         1.101670e+07   \n",
       "std        0.372820      0.364882         0.019174         3.473220e+07   \n",
       "min        0.000000      0.000000        -0.535290         4.761882e+01   \n",
       "25%        0.000000      0.000000        -0.002500         1.070965e+03   \n",
       "50%        0.000000      0.000000         0.000000         2.142827e+03   \n",
       "75%        0.000000      0.000000         0.002506         4.999833e+03   \n",
       "max        1.000000      1.000000         2.815000         3.500000e+08   \n",
       "\n",
       "       intageincome  monthlyincome  \n",
       "count  8.714600e+04   87146.000000  \n",
       "mean   1.830919e+06    5408.266190  \n",
       "std    3.286459e+06    3945.949487  \n",
       "min    8.568000e+04     333.333333  \n",
       "25%    1.075000e+06    3333.333333  \n",
       "50%    1.512000e+06    4750.000000  \n",
       "75%    2.175000e+06    6500.000000  \n",
       "max    8.640000e+08  500000.000000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train.riskflag.isna().sum(), train.loanincomeratio.isna().sum(), train.loanemploymentratio.isna().sum(),  train.intageincome.isna().sum(), train.monthlyincome.isna().sum()\n",
    "# test.riskflag.isna().sum(), test.loanincomeratio.isna().sum(), test.loanemploymentratio.isna().sum(),  test.intageincome.isna().sum(), test.monthlyincome.isna().sum()\n",
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a0842e1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-09T01:04:42.901390Z",
     "iopub.status.busy": "2024-11-09T01:04:42.900356Z",
     "iopub.status.idle": "2024-11-09T01:04:42.912766Z",
     "shell.execute_reply": "2024-11-09T01:04:42.911385Z"
    },
    "papermill": {
     "duration": 0.026206,
     "end_time": "2024-11-09T01:04:42.915659",
     "exception": false,
     "start_time": "2024-11-09T01:04:42.889453",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Difference Columns: ['loan_status']\n",
      "Numeric Cols: \n",
      " ['person_age', 'person_income', 'person_emp_length', 'loan_amnt', 'loan_int_rate', 'loan_percent_income', 'cb_person_cred_hist_length', 'loanincomeratio', 'loanemploymentratio', 'intageincome', 'monthlyincome'] \n",
      "\n",
      "\n",
      "Cat Cols: \n",
      " ['person_home_ownership', 'loan_intent', 'loan_grade', 'cb_person_default_on_file', 'riskflag'] \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define Difference Columns\n",
    "c = list(train.columns)\n",
    "diff = [x for x in c if x not in list(test.columns)]\n",
    "print(f'Difference Columns: {diff}') #should contain target and nothing else...\n",
    "\n",
    "\n",
    "# Define Numeric and Categorical Columns\n",
    "NUM_COLS = list(test.select_dtypes(include=[np.number]).columns) #these should be cast as float for safety\n",
    "NUM_COLS.remove('riskflag')\n",
    "CAT_COLS = [x for x in list(test.columns) if x not in NUM_COLS] #these need to be encoded...\n",
    "\n",
    "print(f\"Numeric Cols: \\n {NUM_COLS} \\n\\n\")\n",
    "print(f\"Cat Cols: \\n {CAT_COLS} \\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cfa1db83",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-09T01:04:42.937412Z",
     "iopub.status.busy": "2024-11-09T01:04:42.936964Z",
     "iopub.status.idle": "2024-11-09T01:04:42.978517Z",
     "shell.execute_reply": "2024-11-09T01:04:42.977178Z"
    },
    "papermill": {
     "duration": 0.055777,
     "end_time": "2024-11-09T01:04:42.981301",
     "exception": false,
     "start_time": "2024-11-09T01:04:42.925524",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person_age\n",
      "27.61228283570101\n",
      "6.127789621020134\n",
      "person_income\n",
      "64899.194283157\n",
      "47351.393843935264\n",
      "person_emp_length\n",
      "4.730165469442086\n",
      "4.025696109983262\n",
      "loan_amnt\n",
      "9361.777385077916\n",
      "5828.985175663818\n",
      "loan_int_rate\n",
      "10.798068299176094\n",
      "3.104952035429868\n",
      "loan_percent_income\n",
      "0.16259924724026345\n",
      "0.09687166606831364\n",
      "cb_person_cred_hist_length\n",
      "5.809285566750051\n",
      "4.033419867682206\n",
      "loanincomeratio\n",
      "0.0004781022821633491\n",
      "0.01917408375808119\n",
      "loanemploymentratio\n",
      "11016704.068540532\n",
      "34732197.12870682\n",
      "intageincome\n",
      "1830919.4381038717\n",
      "3286459.4886769983\n",
      "monthlyincome\n",
      "5408.266190263084\n",
      "3945.9494869946047\n"
     ]
    }
   ],
   "source": [
    "# # data preprocessing steps\n",
    "\n",
    "# Define Target Column\n",
    "target = 'loan_status'\n",
    "\n",
    "# standardize and record numerical column steps\n",
    "col, me, std = [] , [] , []\n",
    "\n",
    "for i in NUM_COLS:\n",
    "    print(i)\n",
    "    m = train[i].mean()\n",
    "    print(m)\n",
    "    s = train[i].std()\n",
    "    print(s)\n",
    "    train[i] = train[i].astype(np.float32)\n",
    "    train[i] = (train[i] - m) / s\n",
    "    test[i] = test[i].astype(np.float32)\n",
    "    test[i] = (test[i] - m) / s\n",
    "    col.append(i)\n",
    "    me.append(m)\n",
    "    std.append(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ffa5d17c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-09T01:04:43.003345Z",
     "iopub.status.busy": "2024-11-09T01:04:43.002294Z",
     "iopub.status.idle": "2024-11-09T01:04:52.222613Z",
     "shell.execute_reply": "2024-11-09T01:04:52.221249Z"
    },
    "papermill": {
     "duration": 9.234276,
     "end_time": "2024-11-09T01:04:52.225674",
     "exception": false,
     "start_time": "2024-11-09T01:04:42.991398",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding person_home_ownership:\n",
      "Completed with 0 notfound errors...\n",
      "Encoding loan_intent:\n",
      "Completed with 0 notfound errors...\n",
      "Encoding loan_grade:\n",
      "Completed with 0 notfound errors...\n",
      "Encoding cb_person_default_on_file:\n",
      "Completed with 0 notfound errors...\n",
      "Encoding riskflag:\n",
      "Completed with 0 notfound errors...\n",
      "Finished Encoding\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# standardize and record categorical column steps  \n",
    "columnindexes = dict()\n",
    "testsetexceptions, CAT_SIZE, CAT_EMB = [] , [] , []\n",
    "\n",
    "# do training data first\n",
    "for col in CAT_COLS:\n",
    "    train[col], columnindexes[col] = train[col].factorize()\n",
    "    CAT_SIZE.append(train[col].max()+2)\n",
    "    CAT_EMB.append(int(np.ceil(np.sqrt( train[col].max()+2) )))\n",
    "\n",
    "# now do test data with indexes built\n",
    "for col in CAT_COLS:\n",
    "    indexer , notfound = [], 0\n",
    "    print(f\"Encoding {col}:\")\n",
    "    for row in range(len(test[col])):\n",
    "        try:\n",
    "            indexer.append(np.where(columnindexes[col]==test[col].iloc[row])[0][0])\n",
    "        except:\n",
    "            indexer.append(-1)\n",
    "            notfound +=1\n",
    "            testsetexceptions.append((row, col, test[col].iloc[row]))\n",
    "    test[col] = indexer\n",
    "    print(f\"Completed with {notfound} notfound errors...\")\n",
    "    \n",
    "print('Finished Encoding')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "01b9714e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-09T01:04:52.247948Z",
     "iopub.status.busy": "2024-11-09T01:04:52.247497Z",
     "iopub.status.idle": "2024-11-09T01:04:52.253795Z",
     "shell.execute_reply": "2024-11-09T01:04:52.252392Z"
    },
    "papermill": {
     "duration": 0.02114,
     "end_time": "2024-11-09T01:04:52.257112",
     "exception": false,
     "start_time": "2024-11-09T01:04:52.235972",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID,  Col,   Item\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "# to see notfound errors uncomment\n",
    "print(\"ID,  Col,   Item\")\n",
    "print(testsetexceptions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0567c369",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-09T01:04:52.279582Z",
     "iopub.status.busy": "2024-11-09T01:04:52.279085Z",
     "iopub.status.idle": "2024-11-09T01:04:54.837037Z",
     "shell.execute_reply": "2024-11-09T01:04:54.835757Z"
    },
    "papermill": {
     "duration": 2.572878,
     "end_time": "2024-11-09T01:04:54.840200",
     "exception": false,
     "start_time": "2024-11-09T01:04:52.267322",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# save data for boosting algos\n",
    "train.to_csv('train.csv', index=True)\n",
    "test.to_csv('test.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "31f80968",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-09T01:04:54.865379Z",
     "iopub.status.busy": "2024-11-09T01:04:54.864201Z",
     "iopub.status.idle": "2024-11-09T01:04:54.877879Z",
     "shell.execute_reply": "2024-11-09T01:04:54.876445Z"
    },
    "papermill": {
     "duration": 0.028935,
     "end_time": "2024-11-09T01:04:54.880750",
     "exception": false,
     "start_time": "2024-11-09T01:04:54.851815",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    xincat = Input(shape=(len(CAT_COLS),))\n",
    "    xembs = []\n",
    "    for i in range(len(CAT_COLS)):\n",
    "        e = tf.keras.layers.Embedding(CAT_SIZE[i],CAT_EMB[i])\n",
    "        x = e(xincat[:,i])\n",
    "        x = tf.keras.layers.Flatten()(x)\n",
    "        xembs.append(x)\n",
    "        \n",
    "    xinnum = Input(shape=(len(NUM_COLS),))\n",
    "    \n",
    "    x = tf.keras.layers.Concatenate(axis=-1)(xembs+[xinnum])\n",
    "    \n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = Dense(1, activation='sigmoid')(x)  #linear for regression, sigmoid (0 to 1), tanh (-1 to 1)\n",
    "    \n",
    "    model = Model(inputs=[xincat,xinnum], outputs = x)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e04435e1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-09T01:04:54.911945Z",
     "iopub.status.busy": "2024-11-09T01:04:54.911502Z",
     "iopub.status.idle": "2024-11-09T01:04:54.918961Z",
     "shell.execute_reply": "2024-11-09T01:04:54.917535Z"
    },
    "papermill": {
     "duration": 0.025867,
     "end_time": "2024-11-09T01:04:54.921712",
     "exception": false,
     "start_time": "2024-11-09T01:04:54.895845",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Define Epochs and Learning Rates\n",
    "EPOCHS = 30\n",
    "LRS = [.002]*2 + [0.001]* 2+ [.0005]*26  \n",
    "#LRS = [.002] * 12\n",
    "\n",
    "# make a function to return the Learning rate from the list\n",
    "def lrfn(epoch):\n",
    "    return LRS[epoch]\n",
    "\n",
    "# make a callback to feed in the learning rate based on the epoch running\n",
    "lr_callback = tf.keras.callbacks.LearningRateScheduler(lrfn, verbose = True)\n",
    "\n",
    "# make softmax function for testing\n",
    "def softmaxer(x):\n",
    "    return round(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d6ccb78f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-09T01:04:54.944672Z",
     "iopub.status.busy": "2024-11-09T01:04:54.944072Z",
     "iopub.status.idle": "2024-11-09T01:30:21.543497Z",
     "shell.execute_reply": "2024-11-09T01:30:21.541918Z"
    },
    "papermill": {
     "duration": 1526.614522,
     "end_time": "2024-11-09T01:30:21.546636",
     "exception": false,
     "start_time": "2024-11-09T01:04:54.932114",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##########################################\n",
      "#####            FOLD 0             #####\n",
      "##########################################\n",
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.002.\n",
      "Epoch 1/30\n",
      "1249/1249 - 13s - 11ms/step - auc: 0.9061 - loss: 0.2393 - val_auc: 0.9249 - val_loss: 0.2034 - learning_rate: 0.0020\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.002.\n",
      "Epoch 2/30\n",
      "1249/1249 - 10s - 8ms/step - auc: 0.9215 - loss: 0.2066 - val_auc: 0.9282 - val_loss: 0.1987 - learning_rate: 0.0020\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 3/30\n",
      "1249/1249 - 10s - 8ms/step - auc: 0.9288 - loss: 0.1942 - val_auc: 0.9297 - val_loss: 0.1928 - learning_rate: 0.0010\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 4/30\n",
      "1249/1249 - 10s - 8ms/step - auc: 0.9311 - loss: 0.1901 - val_auc: 0.9287 - val_loss: 0.1905 - learning_rate: 0.0010\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 0.0005.\n",
      "Epoch 5/30\n",
      "1249/1249 - 10s - 8ms/step - auc: 0.9346 - loss: 0.1832 - val_auc: 0.9304 - val_loss: 0.1884 - learning_rate: 5.0000e-04\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 0.0005.\n",
      "Epoch 6/30\n",
      "1249/1249 - 10s - 8ms/step - auc: 0.9363 - loss: 0.1804 - val_auc: 0.9305 - val_loss: 0.1860 - learning_rate: 5.0000e-04\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 0.0005.\n",
      "Epoch 7/30\n",
      "1249/1249 - 10s - 8ms/step - auc: 0.9373 - loss: 0.1780 - val_auc: 0.9311 - val_loss: 0.1851 - learning_rate: 5.0000e-04\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 0.0005.\n",
      "Epoch 8/30\n",
      "1249/1249 - 10s - 8ms/step - auc: 0.9387 - loss: 0.1765 - val_auc: 0.9310 - val_loss: 0.1850 - learning_rate: 5.0000e-04\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 0.0005.\n",
      "Epoch 9/30\n",
      "1249/1249 - 10s - 8ms/step - auc: 0.9399 - loss: 0.1746 - val_auc: 0.9311 - val_loss: 0.1867 - learning_rate: 5.0000e-04\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 0.0005.\n",
      "Epoch 10/30\n",
      "1249/1249 - 10s - 8ms/step - auc: 0.9411 - loss: 0.1734 - val_auc: 0.9320 - val_loss: 0.1839 - learning_rate: 5.0000e-04\n",
      "\n",
      "Epoch 11: LearningRateScheduler setting learning rate to 0.0005.\n",
      "Epoch 11/30\n",
      "1249/1249 - 10s - 8ms/step - auc: 0.9430 - loss: 0.1702 - val_auc: 0.9290 - val_loss: 0.1889 - learning_rate: 5.0000e-04\n",
      "\n",
      "Epoch 12: LearningRateScheduler setting learning rate to 0.0005.\n",
      "Epoch 12/30\n",
      "1249/1249 - 10s - 8ms/step - auc: 0.9442 - loss: 0.1686 - val_auc: 0.9296 - val_loss: 0.1869 - learning_rate: 5.0000e-04\n",
      "\n",
      "Epoch 13: LearningRateScheduler setting learning rate to 0.0005.\n",
      "Epoch 13/30\n",
      "1249/1249 - 10s - 8ms/step - auc: 0.9455 - loss: 0.1666 - val_auc: 0.9279 - val_loss: 0.1923 - learning_rate: 5.0000e-04\n",
      "\n",
      "Epoch 14: LearningRateScheduler setting learning rate to 0.0005.\n",
      "Epoch 14/30\n",
      "1249/1249 - 10s - 8ms/step - auc: 0.9473 - loss: 0.1635 - val_auc: 0.9279 - val_loss: 0.1922 - learning_rate: 5.0000e-04\n",
      "Epoch 14: early stopping\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "yshape (7263,) predss shape (7263,)\n",
      "ll = 0.183938315135288\n",
      "\n",
      "llsm = 1.970168029117377\n",
      "\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step\n",
      "##########################################\n",
      "#####            FOLD 1             #####\n",
      "##########################################\n",
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.002.\n",
      "Epoch 1/30\n",
      "1249/1249 - 13s - 11ms/step - auc: 0.9082 - loss: 0.2347 - val_auc: 0.9166 - val_loss: 0.2173 - learning_rate: 0.0020\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.002.\n",
      "Epoch 2/30\n",
      "1249/1249 - 10s - 8ms/step - auc: 0.9228 - loss: 0.2049 - val_auc: 0.9153 - val_loss: 0.2118 - learning_rate: 0.0020\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 3/30\n",
      "1249/1249 - 10s - 8ms/step - auc: 0.9288 - loss: 0.1923 - val_auc: 0.9242 - val_loss: 0.2024 - learning_rate: 0.0010\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 4/30\n",
      "1249/1249 - 10s - 8ms/step - auc: 0.9309 - loss: 0.1888 - val_auc: 0.9247 - val_loss: 0.2057 - learning_rate: 0.0010\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 0.0005.\n",
      "Epoch 5/30\n",
      "1249/1249 - 10s - 8ms/step - auc: 0.9348 - loss: 0.1818 - val_auc: 0.9252 - val_loss: 0.2012 - learning_rate: 5.0000e-04\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 0.0005.\n",
      "Epoch 6/30\n",
      "1249/1249 - 10s - 8ms/step - auc: 0.9362 - loss: 0.1795 - val_auc: 0.9247 - val_loss: 0.2006 - learning_rate: 5.0000e-04\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 0.0005.\n",
      "Epoch 7/30\n",
      "1249/1249 - 10s - 8ms/step - auc: 0.9373 - loss: 0.1774 - val_auc: 0.9273 - val_loss: 0.1963 - learning_rate: 5.0000e-04\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 0.0005.\n",
      "Epoch 8/30\n",
      "1249/1249 - 10s - 8ms/step - auc: 0.9383 - loss: 0.1757 - val_auc: 0.9258 - val_loss: 0.1989 - learning_rate: 5.0000e-04\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 0.0005.\n",
      "Epoch 9/30\n",
      "1249/1249 - 10s - 8ms/step - auc: 0.9396 - loss: 0.1737 - val_auc: 0.9275 - val_loss: 0.1984 - learning_rate: 5.0000e-04\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 0.0005.\n",
      "Epoch 10/30\n",
      "1249/1249 - 10s - 8ms/step - auc: 0.9411 - loss: 0.1720 - val_auc: 0.9261 - val_loss: 0.1971 - learning_rate: 5.0000e-04\n",
      "\n",
      "Epoch 11: LearningRateScheduler setting learning rate to 0.0005.\n",
      "Epoch 11/30\n",
      "1249/1249 - 10s - 8ms/step - auc: 0.9426 - loss: 0.1697 - val_auc: 0.9261 - val_loss: 0.1993 - learning_rate: 5.0000e-04\n",
      "\n",
      "Epoch 12: LearningRateScheduler setting learning rate to 0.0005.\n",
      "Epoch 12/30\n",
      "1249/1249 - 10s - 8ms/step - auc: 0.9447 - loss: 0.1684 - val_auc: 0.9271 - val_loss: 0.1991 - learning_rate: 5.0000e-04\n",
      "\n",
      "Epoch 13: LearningRateScheduler setting learning rate to 0.0005.\n",
      "Epoch 13/30\n",
      "1249/1249 - 10s - 8ms/step - auc: 0.9463 - loss: 0.1654 - val_auc: 0.9231 - val_loss: 0.2037 - learning_rate: 5.0000e-04\n",
      "Epoch 13: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "yshape (7263,) predss shape (7263,)\n",
      "ll = 0.19839079526717399\n",
      "\n",
      "llsm = 2.2679264214273083\n",
      "\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step\n",
      "##########################################\n",
      "#####            FOLD 2             #####\n",
      "##########################################\n",
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.002.\n",
      "Epoch 1/30\n",
      "1249/1249 - 14s - 11ms/step - auc: 0.9071 - loss: 0.2386 - val_auc: 0.9193 - val_loss: 0.2181 - learning_rate: 0.0020\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.002.\n",
      "Epoch 2/30\n",
      "1249/1249 - 10s - 8ms/step - auc: 0.9226 - loss: 0.2046 - val_auc: 0.9243 - val_loss: 0.2120 - learning_rate: 0.0020\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 3/30\n",
      "1249/1249 - 10s - 8ms/step - auc: 0.9292 - loss: 0.1916 - val_auc: 0.9262 - val_loss: 0.2018 - learning_rate: 0.0010\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 4/30\n",
      "1249/1249 - 10s - 8ms/step - auc: 0.9318 - loss: 0.1887 - val_auc: 0.9245 - val_loss: 0.2013 - learning_rate: 0.0010\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 0.0005.\n",
      "Epoch 5/30\n",
      "1249/1249 - 20s - 16ms/step - auc: 0.9351 - loss: 0.1819 - val_auc: 0.9272 - val_loss: 0.2026 - learning_rate: 5.0000e-04\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 0.0005.\n",
      "Epoch 6/30\n",
      "1249/1249 - 10s - 8ms/step - auc: 0.9362 - loss: 0.1802 - val_auc: 0.9270 - val_loss: 0.1986 - learning_rate: 5.0000e-04\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 0.0005.\n",
      "Epoch 7/30\n",
      "1249/1249 - 20s - 16ms/step - auc: 0.9370 - loss: 0.1788 - val_auc: 0.9278 - val_loss: 0.1996 - learning_rate: 5.0000e-04\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 0.0005.\n",
      "Epoch 8/30\n",
      "1249/1249 - 10s - 8ms/step - auc: 0.9381 - loss: 0.1770 - val_auc: 0.9272 - val_loss: 0.1988 - learning_rate: 5.0000e-04\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 0.0005.\n",
      "Epoch 9/30\n",
      "1249/1249 - 10s - 8ms/step - auc: 0.9395 - loss: 0.1751 - val_auc: 0.9264 - val_loss: 0.1983 - learning_rate: 5.0000e-04\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 0.0005.\n",
      "Epoch 10/30\n",
      "1249/1249 - 10s - 8ms/step - auc: 0.9406 - loss: 0.1733 - val_auc: 0.9249 - val_loss: 0.1994 - learning_rate: 5.0000e-04\n",
      "\n",
      "Epoch 11: LearningRateScheduler setting learning rate to 0.0005.\n",
      "Epoch 11/30\n",
      "1249/1249 - 10s - 8ms/step - auc: 0.9417 - loss: 0.1714 - val_auc: 0.9260 - val_loss: 0.2001 - learning_rate: 5.0000e-04\n",
      "Epoch 11: early stopping\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "yshape (7262,) predss shape (7262,)\n",
      "ll = 0.19962353156854876\n",
      "\n",
      "llsm = 2.2186054895256633\n",
      "\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step\n",
      "##########################################\n",
      "#####            FOLD 3             #####\n",
      "##########################################\n",
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.002.\n",
      "Epoch 1/30\n",
      "1249/1249 - 13s - 11ms/step - auc: 0.9070 - loss: 0.2382 - val_auc: 0.9188 - val_loss: 0.2135 - learning_rate: 0.0020\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.002.\n",
      "Epoch 2/30\n",
      "1249/1249 - 10s - 8ms/step - auc: 0.9215 - loss: 0.2059 - val_auc: 0.9282 - val_loss: 0.2003 - learning_rate: 0.0020\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 3/30\n",
      "1249/1249 - 10s - 8ms/step - auc: 0.9296 - loss: 0.1927 - val_auc: 0.9279 - val_loss: 0.1988 - learning_rate: 0.0010\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 4/30\n",
      "1249/1249 - 10s - 8ms/step - auc: 0.9315 - loss: 0.1898 - val_auc: 0.9289 - val_loss: 0.1965 - learning_rate: 0.0010\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 0.0005.\n",
      "Epoch 5/30\n",
      "1249/1249 - 10s - 8ms/step - auc: 0.9342 - loss: 0.1833 - val_auc: 0.9287 - val_loss: 0.1910 - learning_rate: 5.0000e-04\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 0.0005.\n",
      "Epoch 6/30\n",
      "1249/1249 - 10s - 8ms/step - auc: 0.9357 - loss: 0.1807 - val_auc: 0.9305 - val_loss: 0.1913 - learning_rate: 5.0000e-04\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 0.0005.\n",
      "Epoch 7/30\n",
      "1249/1249 - 10s - 8ms/step - auc: 0.9365 - loss: 0.1788 - val_auc: 0.9277 - val_loss: 0.1925 - learning_rate: 5.0000e-04\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 0.0005.\n",
      "Epoch 8/30\n",
      "1249/1249 - 10s - 8ms/step - auc: 0.9375 - loss: 0.1775 - val_auc: 0.9296 - val_loss: 0.1941 - learning_rate: 5.0000e-04\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 0.0005.\n",
      "Epoch 9/30\n",
      "1249/1249 - 10s - 8ms/step - auc: 0.9387 - loss: 0.1759 - val_auc: 0.9287 - val_loss: 0.1923 - learning_rate: 5.0000e-04\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 0.0005.\n",
      "Epoch 10/30\n",
      "1249/1249 - 10s - 8ms/step - auc: 0.9396 - loss: 0.1742 - val_auc: 0.9268 - val_loss: 0.1900 - learning_rate: 5.0000e-04\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "yshape (7262,) predss shape (7262,)\n",
      "ll = 0.1912881279910203\n",
      "\n",
      "llsm = 2.084595761970422\n",
      "\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step\n",
      "##########################################\n",
      "#####            FOLD 4             #####\n",
      "##########################################\n",
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.002.\n",
      "Epoch 1/30\n",
      "1249/1249 - 14s - 11ms/step - auc: 0.9060 - loss: 0.2392 - val_auc: 0.9237 - val_loss: 0.2051 - learning_rate: 0.0020\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.002.\n",
      "Epoch 2/30\n",
      "1249/1249 - 10s - 8ms/step - auc: 0.9217 - loss: 0.2064 - val_auc: 0.9260 - val_loss: 0.2016 - learning_rate: 0.0020\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 3/30\n",
      "1249/1249 - 10s - 8ms/step - auc: 0.9290 - loss: 0.1930 - val_auc: 0.9298 - val_loss: 0.1904 - learning_rate: 0.0010\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 4/30\n",
      "1249/1249 - 10s - 8ms/step - auc: 0.9313 - loss: 0.1896 - val_auc: 0.9291 - val_loss: 0.1946 - learning_rate: 0.0010\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 0.0005.\n",
      "Epoch 5/30\n",
      "1249/1249 - 10s - 8ms/step - auc: 0.9349 - loss: 0.1825 - val_auc: 0.9313 - val_loss: 0.1870 - learning_rate: 5.0000e-04\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 0.0005.\n",
      "Epoch 6/30\n",
      "1249/1249 - 10s - 8ms/step - auc: 0.9363 - loss: 0.1803 - val_auc: 0.9306 - val_loss: 0.1917 - learning_rate: 5.0000e-04\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 0.0005.\n",
      "Epoch 7/30\n",
      "1249/1249 - 10s - 8ms/step - auc: 0.9369 - loss: 0.1791 - val_auc: 0.9338 - val_loss: 0.1841 - learning_rate: 5.0000e-04\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 0.0005.\n",
      "Epoch 8/30\n",
      "1249/1249 - 10s - 8ms/step - auc: 0.9383 - loss: 0.1773 - val_auc: 0.9319 - val_loss: 0.1870 - learning_rate: 5.0000e-04\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 0.0005.\n",
      "Epoch 9/30\n",
      "1249/1249 - 10s - 8ms/step - auc: 0.9391 - loss: 0.1755 - val_auc: 0.9340 - val_loss: 0.1844 - learning_rate: 5.0000e-04\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 0.0005.\n",
      "Epoch 10/30\n",
      "1249/1249 - 10s - 8ms/step - auc: 0.9401 - loss: 0.1742 - val_auc: 0.9339 - val_loss: 0.1828 - learning_rate: 5.0000e-04\n",
      "\n",
      "Epoch 11: LearningRateScheduler setting learning rate to 0.0005.\n",
      "Epoch 11/30\n",
      "1249/1249 - 10s - 8ms/step - auc: 0.9411 - loss: 0.1722 - val_auc: 0.9322 - val_loss: 0.1877 - learning_rate: 5.0000e-04\n",
      "\n",
      "Epoch 12: LearningRateScheduler setting learning rate to 0.0005.\n",
      "Epoch 12/30\n",
      "1249/1249 - 10s - 8ms/step - auc: 0.9422 - loss: 0.1711 - val_auc: 0.9341 - val_loss: 0.1873 - learning_rate: 5.0000e-04\n",
      "\n",
      "Epoch 13: LearningRateScheduler setting learning rate to 0.0005.\n",
      "Epoch 13/30\n",
      "1249/1249 - 10s - 8ms/step - auc: 0.9437 - loss: 0.1693 - val_auc: 0.9337 - val_loss: 0.1838 - learning_rate: 5.0000e-04\n",
      "\n",
      "Epoch 14: LearningRateScheduler setting learning rate to 0.0005.\n",
      "Epoch 14/30\n",
      "1249/1249 - 10s - 8ms/step - auc: 0.9451 - loss: 0.1673 - val_auc: 0.9320 - val_loss: 0.1875 - learning_rate: 5.0000e-04\n",
      "\n",
      "Epoch 15: LearningRateScheduler setting learning rate to 0.0005.\n",
      "Epoch 15/30\n",
      "1249/1249 - 10s - 8ms/step - auc: 0.9463 - loss: 0.1653 - val_auc: 0.9340 - val_loss: 0.1878 - learning_rate: 5.0000e-04\n",
      "\n",
      "Epoch 16: LearningRateScheduler setting learning rate to 0.0005.\n",
      "Epoch 16/30\n",
      "1249/1249 - 10s - 8ms/step - auc: 0.9475 - loss: 0.1633 - val_auc: 0.9331 - val_loss: 0.1890 - learning_rate: 5.0000e-04\n",
      "Epoch 16: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "yshape (7262,) predss shape (7262,)\n",
      "ll = 0.18729054111894272\n",
      "\n",
      "llsm = 1.995255943600261\n",
      "\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step\n",
      "##########################################\n",
      "#####            FOLD 5             #####\n",
      "##########################################\n",
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.002.\n",
      "Epoch 1/30\n",
      "1249/1249 - 13s - 11ms/step - auc: 0.9057 - loss: 0.2428 - val_auc: 0.9250 - val_loss: 0.2117 - learning_rate: 0.0020\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.002.\n",
      "Epoch 2/30\n",
      "1249/1249 - 11s - 8ms/step - auc: 0.9215 - loss: 0.2058 - val_auc: 0.9273 - val_loss: 0.2095 - learning_rate: 0.0020\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 3/30\n",
      "1249/1249 - 10s - 8ms/step - auc: 0.9286 - loss: 0.1926 - val_auc: 0.9302 - val_loss: 0.1975 - learning_rate: 0.0010\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 4/30\n",
      "1249/1249 - 10s - 8ms/step - auc: 0.9307 - loss: 0.1895 - val_auc: 0.9299 - val_loss: 0.1988 - learning_rate: 0.0010\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 0.0005.\n",
      "Epoch 5/30\n",
      "1249/1249 - 10s - 8ms/step - auc: 0.9338 - loss: 0.1829 - val_auc: 0.9328 - val_loss: 0.1951 - learning_rate: 5.0000e-04\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 0.0005.\n",
      "Epoch 6/30\n",
      "1249/1249 - 10s - 8ms/step - auc: 0.9351 - loss: 0.1812 - val_auc: 0.9331 - val_loss: 0.1925 - learning_rate: 5.0000e-04\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 0.0005.\n",
      "Epoch 7/30\n",
      "1249/1249 - 10s - 8ms/step - auc: 0.9360 - loss: 0.1798 - val_auc: 0.9332 - val_loss: 0.1904 - learning_rate: 5.0000e-04\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 0.0005.\n",
      "Epoch 8/30\n",
      "1249/1249 - 10s - 8ms/step - auc: 0.9370 - loss: 0.1785 - val_auc: 0.9324 - val_loss: 0.1948 - learning_rate: 5.0000e-04\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 0.0005.\n",
      "Epoch 9/30\n",
      "1249/1249 - 10s - 8ms/step - auc: 0.9381 - loss: 0.1765 - val_auc: 0.9321 - val_loss: 0.1918 - learning_rate: 5.0000e-04\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 0.0005.\n",
      "Epoch 10/30\n",
      "1249/1249 - 10s - 8ms/step - auc: 0.9394 - loss: 0.1747 - val_auc: 0.9326 - val_loss: 0.1925 - learning_rate: 5.0000e-04\n",
      "\n",
      "Epoch 11: LearningRateScheduler setting learning rate to 0.0005.\n",
      "Epoch 11/30\n",
      "1249/1249 - 10s - 8ms/step - auc: 0.9407 - loss: 0.1726 - val_auc: 0.9300 - val_loss: 0.1938 - learning_rate: 5.0000e-04\n",
      "Epoch 11: early stopping\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "yshape (7262,) predss shape (7262,)\n",
      "ll = 0.1904024279606246\n",
      "\n",
      "llsm = 2.129265671155502\n",
      "\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step\n",
      "##########################################\n",
      "#####            FOLD 6             #####\n",
      "##########################################\n",
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.002.\n",
      "Epoch 1/30\n",
      "1249/1249 - 14s - 11ms/step - auc: 0.9057 - loss: 0.2375 - val_auc: 0.9262 - val_loss: 0.2130 - learning_rate: 0.0020\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.002.\n",
      "Epoch 2/30\n",
      "1249/1249 - 11s - 9ms/step - auc: 0.9209 - loss: 0.2068 - val_auc: 0.9318 - val_loss: 0.1941 - learning_rate: 0.0020\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 3/30\n",
      "1249/1249 - 11s - 8ms/step - auc: 0.9282 - loss: 0.1941 - val_auc: 0.9345 - val_loss: 0.1919 - learning_rate: 0.0010\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 4/30\n",
      "1249/1249 - 10s - 8ms/step - auc: 0.9304 - loss: 0.1905 - val_auc: 0.9327 - val_loss: 0.1853 - learning_rate: 0.0010\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 0.0005.\n",
      "Epoch 5/30\n",
      "1249/1249 - 11s - 8ms/step - auc: 0.9339 - loss: 0.1840 - val_auc: 0.9382 - val_loss: 0.1761 - learning_rate: 5.0000e-04\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 0.0005.\n",
      "Epoch 6/30\n",
      "1249/1249 - 10s - 8ms/step - auc: 0.9349 - loss: 0.1821 - val_auc: 0.9387 - val_loss: 0.1744 - learning_rate: 5.0000e-04\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 0.0005.\n",
      "Epoch 7/30\n",
      "1249/1249 - 10s - 8ms/step - auc: 0.9363 - loss: 0.1801 - val_auc: 0.9371 - val_loss: 0.1788 - learning_rate: 5.0000e-04\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 0.0005.\n",
      "Epoch 8/30\n",
      "1249/1249 - 10s - 8ms/step - auc: 0.9371 - loss: 0.1787 - val_auc: 0.9358 - val_loss: 0.1765 - learning_rate: 5.0000e-04\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 0.0005.\n",
      "Epoch 9/30\n",
      "1249/1249 - 10s - 8ms/step - auc: 0.9382 - loss: 0.1766 - val_auc: 0.9360 - val_loss: 0.1754 - learning_rate: 5.0000e-04\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 0.0005.\n",
      "Epoch 10/30\n",
      "1249/1249 - 10s - 8ms/step - auc: 0.9399 - loss: 0.1751 - val_auc: 0.9357 - val_loss: 0.1754 - learning_rate: 5.0000e-04\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "yshape (7262,) predss shape (7262,)\n",
      "ll = 0.1743778166728064\n",
      "\n",
      "llsm = 1.89102615550174\n",
      "\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step\n",
      "##########################################\n",
      "#####            FOLD 7             #####\n",
      "##########################################\n",
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.002.\n",
      "Epoch 1/30\n",
      "1249/1249 - 14s - 11ms/step - auc: 0.9053 - loss: 0.2444 - val_auc: 0.9250 - val_loss: 0.2126 - learning_rate: 0.0020\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.002.\n",
      "Epoch 2/30\n",
      "1249/1249 - 20s - 16ms/step - auc: 0.9209 - loss: 0.2066 - val_auc: 0.9307 - val_loss: 0.1978 - learning_rate: 0.0020\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 3/30\n",
      "1249/1249 - 10s - 8ms/step - auc: 0.9274 - loss: 0.1943 - val_auc: 0.9320 - val_loss: 0.1971 - learning_rate: 0.0010\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 4/30\n",
      "1249/1249 - 10s - 8ms/step - auc: 0.9294 - loss: 0.1910 - val_auc: 0.9350 - val_loss: 0.1903 - learning_rate: 0.0010\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 0.0005.\n",
      "Epoch 5/30\n",
      "1249/1249 - 10s - 8ms/step - auc: 0.9339 - loss: 0.1837 - val_auc: 0.9344 - val_loss: 0.1876 - learning_rate: 5.0000e-04\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 0.0005.\n",
      "Epoch 6/30\n",
      "1249/1249 - 10s - 8ms/step - auc: 0.9351 - loss: 0.1822 - val_auc: 0.9359 - val_loss: 0.1864 - learning_rate: 5.0000e-04\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 0.0005.\n",
      "Epoch 7/30\n",
      "1249/1249 - 10s - 8ms/step - auc: 0.9362 - loss: 0.1796 - val_auc: 0.9345 - val_loss: 0.1874 - learning_rate: 5.0000e-04\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 0.0005.\n",
      "Epoch 8/30\n",
      "1249/1249 - 10s - 8ms/step - auc: 0.9372 - loss: 0.1782 - val_auc: 0.9355 - val_loss: 0.1864 - learning_rate: 5.0000e-04\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 0.0005.\n",
      "Epoch 9/30\n",
      "1249/1249 - 10s - 8ms/step - auc: 0.9382 - loss: 0.1767 - val_auc: 0.9332 - val_loss: 0.1860 - learning_rate: 5.0000e-04\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 0.0005.\n",
      "Epoch 10/30\n",
      "1249/1249 - 10s - 8ms/step - auc: 0.9399 - loss: 0.1746 - val_auc: 0.9332 - val_loss: 0.1899 - learning_rate: 5.0000e-04\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "yshape (7262,) predss shape (7262,)\n",
      "ll = 0.18640704591676077\n",
      "\n",
      "llsm = 2.0250358830569812\n",
      "\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step\n",
      "##########################################\n",
      "#####            FOLD 8             #####\n",
      "##########################################\n",
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.002.\n",
      "Epoch 1/30\n",
      "1249/1249 - 14s - 11ms/step - auc: 0.9071 - loss: 0.2370 - val_auc: 0.9178 - val_loss: 0.2108 - learning_rate: 0.0020\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.002.\n",
      "Epoch 2/30\n",
      "1249/1249 - 10s - 8ms/step - auc: 0.9217 - loss: 0.2069 - val_auc: 0.9239 - val_loss: 0.1976 - learning_rate: 0.0020\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 3/30\n",
      "1249/1249 - 10s - 8ms/step - auc: 0.9286 - loss: 0.1942 - val_auc: 0.9279 - val_loss: 0.1857 - learning_rate: 0.0010\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 4/30\n",
      "1249/1249 - 10s - 8ms/step - auc: 0.9312 - loss: 0.1905 - val_auc: 0.9290 - val_loss: 0.1832 - learning_rate: 0.0010\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 0.0005.\n",
      "Epoch 5/30\n",
      "1249/1249 - 10s - 8ms/step - auc: 0.9341 - loss: 0.1838 - val_auc: 0.9296 - val_loss: 0.1810 - learning_rate: 5.0000e-04\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 0.0005.\n",
      "Epoch 6/30\n",
      "1249/1249 - 10s - 8ms/step - auc: 0.9354 - loss: 0.1816 - val_auc: 0.9304 - val_loss: 0.1822 - learning_rate: 5.0000e-04\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 0.0005.\n",
      "Epoch 7/30\n",
      "1249/1249 - 10s - 8ms/step - auc: 0.9362 - loss: 0.1804 - val_auc: 0.9295 - val_loss: 0.1820 - learning_rate: 5.0000e-04\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 0.0005.\n",
      "Epoch 8/30\n",
      "1249/1249 - 11s - 8ms/step - auc: 0.9377 - loss: 0.1787 - val_auc: 0.9298 - val_loss: 0.1813 - learning_rate: 5.0000e-04\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 0.0005.\n",
      "Epoch 9/30\n",
      "1249/1249 - 10s - 8ms/step - auc: 0.9388 - loss: 0.1765 - val_auc: 0.9321 - val_loss: 0.1826 - learning_rate: 5.0000e-04\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 0.0005.\n",
      "Epoch 10/30\n",
      "1249/1249 - 10s - 8ms/step - auc: 0.9395 - loss: 0.1755 - val_auc: 0.9301 - val_loss: 0.1828 - learning_rate: 5.0000e-04\n",
      "\n",
      "Epoch 11: LearningRateScheduler setting learning rate to 0.0005.\n",
      "Epoch 11/30\n",
      "1249/1249 - 10s - 8ms/step - auc: 0.9411 - loss: 0.1733 - val_auc: 0.9303 - val_loss: 0.1815 - learning_rate: 5.0000e-04\n",
      "\n",
      "Epoch 12: LearningRateScheduler setting learning rate to 0.0005.\n",
      "Epoch 12/30\n",
      "1249/1249 - 10s - 8ms/step - auc: 0.9423 - loss: 0.1717 - val_auc: 0.9274 - val_loss: 0.1853 - learning_rate: 5.0000e-04\n",
      "\n",
      "Epoch 13: LearningRateScheduler setting learning rate to 0.0005.\n",
      "Epoch 13/30\n",
      "1249/1249 - 10s - 8ms/step - auc: 0.9439 - loss: 0.1694 - val_auc: 0.9265 - val_loss: 0.1855 - learning_rate: 5.0000e-04\n",
      "Epoch 13: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "yshape (7262,) predss shape (7262,)\n",
      "ll = 0.18261477929449332\n",
      "\n",
      "llsm = 2.0101459133286212\n",
      "\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step\n",
      "##########################################\n",
      "#####            FOLD 9             #####\n",
      "##########################################\n",
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.002.\n",
      "Epoch 1/30\n",
      "1249/1249 - 14s - 11ms/step - auc: 0.9056 - loss: 0.2378 - val_auc: 0.9274 - val_loss: 0.2151 - learning_rate: 0.0020\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.002.\n",
      "Epoch 2/30\n",
      "1249/1249 - 10s - 8ms/step - auc: 0.9201 - loss: 0.2092 - val_auc: 0.9293 - val_loss: 0.2066 - learning_rate: 0.0020\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 3/30\n",
      "1249/1249 - 10s - 8ms/step - auc: 0.9263 - loss: 0.1957 - val_auc: 0.9355 - val_loss: 0.1861 - learning_rate: 0.0010\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 4/30\n",
      "1249/1249 - 10s - 8ms/step - auc: 0.9289 - loss: 0.1916 - val_auc: 0.9353 - val_loss: 0.1866 - learning_rate: 0.0010\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 0.0005.\n",
      "Epoch 5/30\n",
      "1249/1249 - 10s - 8ms/step - auc: 0.9333 - loss: 0.1844 - val_auc: 0.9383 - val_loss: 0.1809 - learning_rate: 5.0000e-04\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 0.0005.\n",
      "Epoch 6/30\n",
      "1249/1249 - 10s - 8ms/step - auc: 0.9351 - loss: 0.1813 - val_auc: 0.9380 - val_loss: 0.1835 - learning_rate: 5.0000e-04\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 0.0005.\n",
      "Epoch 7/30\n",
      "1249/1249 - 10s - 8ms/step - auc: 0.9363 - loss: 0.1791 - val_auc: 0.9391 - val_loss: 0.1798 - learning_rate: 5.0000e-04\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 0.0005.\n",
      "Epoch 8/30\n",
      "1249/1249 - 20s - 16ms/step - auc: 0.9380 - loss: 0.1770 - val_auc: 0.9387 - val_loss: 0.1797 - learning_rate: 5.0000e-04\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 0.0005.\n",
      "Epoch 9/30\n",
      "1249/1249 - 10s - 8ms/step - auc: 0.9391 - loss: 0.1755 - val_auc: 0.9379 - val_loss: 0.1818 - learning_rate: 5.0000e-04\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 0.0005.\n",
      "Epoch 10/30\n",
      "1249/1249 - 10s - 8ms/step - auc: 0.9406 - loss: 0.1734 - val_auc: 0.9387 - val_loss: 0.1782 - learning_rate: 5.0000e-04\n",
      "\n",
      "Epoch 11: LearningRateScheduler setting learning rate to 0.0005.\n",
      "Epoch 11/30\n",
      "1249/1249 - 10s - 8ms/step - auc: 0.9422 - loss: 0.1712 - val_auc: 0.9359 - val_loss: 0.1808 - learning_rate: 5.0000e-04\n",
      "Epoch 11: early stopping\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "yshape (7262,) predss shape (7262,)\n",
      "ll = 0.17975066930740904\n",
      "\n",
      "llsm = 1.9853292971146876\n",
      "\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step\n",
      "##########################################\n",
      "#####            FOLD 10             #####\n",
      "##########################################\n",
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.002.\n",
      "Epoch 1/30\n",
      "1249/1249 - 14s - 11ms/step - auc: 0.9056 - loss: 0.2384 - val_auc: 0.9203 - val_loss: 0.2201 - learning_rate: 0.0020\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.002.\n",
      "Epoch 2/30\n",
      "1249/1249 - 10s - 8ms/step - auc: 0.9216 - loss: 0.2066 - val_auc: 0.9266 - val_loss: 0.2032 - learning_rate: 0.0020\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 3/30\n",
      "1249/1249 - 10s - 8ms/step - auc: 0.9281 - loss: 0.1939 - val_auc: 0.9303 - val_loss: 0.1927 - learning_rate: 0.0010\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 4/30\n",
      "1249/1249 - 10s - 8ms/step - auc: 0.9304 - loss: 0.1904 - val_auc: 0.9309 - val_loss: 0.1920 - learning_rate: 0.0010\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 0.0005.\n",
      "Epoch 5/30\n",
      "1249/1249 - 10s - 8ms/step - auc: 0.9340 - loss: 0.1834 - val_auc: 0.9329 - val_loss: 0.1903 - learning_rate: 5.0000e-04\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 0.0005.\n",
      "Epoch 6/30\n",
      "1249/1249 - 10s - 8ms/step - auc: 0.9353 - loss: 0.1807 - val_auc: 0.9316 - val_loss: 0.1900 - learning_rate: 5.0000e-04\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 0.0005.\n",
      "Epoch 7/30\n",
      "1249/1249 - 10s - 8ms/step - auc: 0.9363 - loss: 0.1790 - val_auc: 0.9317 - val_loss: 0.1881 - learning_rate: 5.0000e-04\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 0.0005.\n",
      "Epoch 8/30\n",
      "1249/1249 - 20s - 16ms/step - auc: 0.9376 - loss: 0.1774 - val_auc: 0.9313 - val_loss: 0.1874 - learning_rate: 5.0000e-04\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 0.0005.\n",
      "Epoch 9/30\n",
      "1249/1249 - 10s - 8ms/step - auc: 0.9389 - loss: 0.1749 - val_auc: 0.9313 - val_loss: 0.1893 - learning_rate: 5.0000e-04\n",
      "Epoch 9: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "yshape (7262,) predss shape (7262,)\n",
      "ll = 0.1902601861905933\n",
      "\n",
      "llsm = 2.039925852785341\n",
      "\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step\n",
      "##########################################\n",
      "#####            FOLD 11             #####\n",
      "##########################################\n",
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.002.\n",
      "Epoch 1/30\n",
      "1249/1249 - 14s - 11ms/step - auc: 0.9076 - loss: 0.2378 - val_auc: 0.9225 - val_loss: 0.2057 - learning_rate: 0.0020\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.002.\n",
      "Epoch 2/30\n",
      "1249/1249 - 10s - 8ms/step - auc: 0.9226 - loss: 0.2061 - val_auc: 0.9226 - val_loss: 0.1989 - learning_rate: 0.0020\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 3/30\n",
      "1249/1249 - 10s - 8ms/step - auc: 0.9285 - loss: 0.1940 - val_auc: 0.9293 - val_loss: 0.1894 - learning_rate: 0.0010\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 4/30\n",
      "1249/1249 - 10s - 8ms/step - auc: 0.9307 - loss: 0.1912 - val_auc: 0.9300 - val_loss: 0.1842 - learning_rate: 0.0010\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 0.0005.\n",
      "Epoch 5/30\n",
      "1249/1249 - 10s - 8ms/step - auc: 0.9343 - loss: 0.1844 - val_auc: 0.9311 - val_loss: 0.1812 - learning_rate: 5.0000e-04\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 0.0005.\n",
      "Epoch 6/30\n",
      "1249/1249 - 10s - 8ms/step - auc: 0.9355 - loss: 0.1819 - val_auc: 0.9307 - val_loss: 0.1839 - learning_rate: 5.0000e-04\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 0.0005.\n",
      "Epoch 7/30\n",
      "1249/1249 - 10s - 8ms/step - auc: 0.9364 - loss: 0.1802 - val_auc: 0.9303 - val_loss: 0.1897 - learning_rate: 5.0000e-04\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 0.0005.\n",
      "Epoch 8/30\n",
      "1249/1249 - 10s - 8ms/step - auc: 0.9375 - loss: 0.1787 - val_auc: 0.9296 - val_loss: 0.1863 - learning_rate: 5.0000e-04\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 0.0005.\n",
      "Epoch 9/30\n",
      "1249/1249 - 10s - 8ms/step - auc: 0.9388 - loss: 0.1772 - val_auc: 0.9300 - val_loss: 0.1818 - learning_rate: 5.0000e-04\n",
      "Epoch 9: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "yshape (7262,) predss shape (7262,)\n",
      "ll = 0.18116781217189884\n",
      "\n",
      "llsm = 1.9754026506291142\n",
      "\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step\n",
      "Overall CV LL = 0.18712609679348333\n",
      "Overall CV LL = 2.049391854394642\n"
     ]
    }
   ],
   "source": [
    "# Define KFOLD the training set\n",
    "FOLDS = 12\n",
    "kf = KFold(n_splits = FOLDS, random_state=12, shuffle =True)\n",
    "\n",
    "#prepare test data once (for speed)\n",
    "testcats = np.asarray(test.loc[:,CAT_COLS].values).astype(np.float32)\n",
    "testnums = np.asarray(test.loc[:,NUM_COLS].values).astype(np.float32)\n",
    "\n",
    "# make oof placeholder\n",
    "oof = np.zeros(len(train))\n",
    "oofsm = np.zeros(len(train))\n",
    "\n",
    "# loop through the folds, training, etc...\n",
    "for i , (train_index, test_index) in enumerate(kf.split(train)):\n",
    "    \n",
    "    # define training set\n",
    "    Xtraincats = train.loc[train_index,CAT_COLS].values\n",
    "    Xtrainnums = train.loc[train_index,NUM_COLS].values\n",
    "    Ytrain = np.array(train.loc[train_index, target].values)\n",
    "    Ytrain = Ytrain.reshape(-1,1)\n",
    "    \n",
    "    #define validation set\n",
    "    Xvalcats = train.loc[test_index,CAT_COLS].values\n",
    "    Xvalnums = train.loc[test_index,NUM_COLS].values\n",
    "    Yval = np.array(train.loc[test_index, target].values)\n",
    "    Yval = Yval.reshape(-1,1)\n",
    "    \n",
    "    #reporting\n",
    "    print('#'*42)\n",
    "    print(f'#####            FOLD {i}             #####')\n",
    "    print('#'*42)\n",
    "    \n",
    "    # clear the Keras session, and build the model\n",
    "    K.clear_session()\n",
    "    # freshened early stopping callback\n",
    "    earlyst = tf.keras.callbacks.EarlyStopping(\n",
    "                monitor='val_auc',\n",
    "#                 monitor='val_binary_crossentropy',\n",
    "                patience=4,    verbose=1,    mode='max',    restore_best_weights=True)\n",
    "\n",
    "    model = build_model()\n",
    "    model.compile(optimizer = tf.keras.optimizers.Adam(0.001),\n",
    "                 loss = \"binary_crossentropy\",\n",
    "                 metrics = [tf.keras.metrics.AUC()]\n",
    "                 #[tf.keras.metrics.BinaryCrossentropy()]\n",
    "                 )\n",
    "    \n",
    "    # fit\n",
    "    model.fit([Xtraincats,Xtrainnums], Ytrain,\n",
    "             validation_data = ([Xvalcats,Xvalnums],Yval),\n",
    "             callbacks = [lr_callback,earlyst],\n",
    "             batch_size=64, epochs = EPOCHS, verbose=2)\n",
    "    \n",
    "    # ll validate\n",
    "    preds = model.predict([Xvalcats,Xvalnums], verbose =1, batch_size=512).flatten()\n",
    "    predss = pd.Series(np.squeeze(preds))\n",
    "    ys = pd.Series(np.squeeze(Yval))\n",
    "    print(f\"yshape {ys.shape} predss shape {predss.shape}\")\n",
    "    ll =  log_loss( ys, predss, normalize=True)\n",
    "    ras = roc_auc_score(ys, predss,average='weighted')\n",
    "    \n",
    "    # softmax validate \n",
    "    predss2 = predss.apply(lambda x : softmaxer(x))\n",
    "    llsm =  log_loss(ys, predss2,  normalize=True)\n",
    "    \n",
    "    if i < FOLDS: \n",
    "        oof[test_index] = predss\n",
    "        oofsm[test_index] = predss2\n",
    "        \n",
    "    print(f\"ll = {ll}\\n\")\n",
    "    print(f\"llsm = {llsm}\\n\")\n",
    "    \n",
    "    # run on test set\n",
    "    testpreds = model.predict([testcats,testnums], verbose=1, batch_size=512).flatten()\n",
    "    if i==0: outs = pd.Series(np.squeeze(testpreds))\n",
    "    else: outs += pd.Series(np.squeeze(testpreds))\n",
    "\n",
    "\n",
    "\n",
    "# get an average of test set predictions   \n",
    "outs /= FOLDS\n",
    "\n",
    "# Compute and display total Loss\n",
    "ll = log_loss(train[target].values,oof, normalize=True )\n",
    "print(\"Overall CV LL =\",ll)\n",
    "ll2 = log_loss(train[target].values,oofsm, normalize=True )\n",
    "print(\"Overall CV LL =\",ll2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "abfba359",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-09T01:30:21.711990Z",
     "iopub.status.busy": "2024-11-09T01:30:21.711537Z",
     "iopub.status.idle": "2024-11-09T01:30:22.133242Z",
     "shell.execute_reply": "2024-11-09T01:30:22.131837Z"
    },
    "papermill": {
     "duration": 0.505514,
     "end_time": "2024-11-09T01:30:22.136280",
     "exception": false,
     "start_time": "2024-11-09T01:30:21.630766",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve \n",
    "\n",
    "# Calculate AUC\n",
    "fpr, tpr, thresholds  = roc_curve(train[target], oof)\n",
    "auc = roc_auc_score(train[target], oof)\n",
    "# Plot ROC curve\n",
    "plt.plot(fpr, tpr, label=f'AUC = {auc:.7f}')\n",
    "plt.plot([0, 1], [0, 1], 'k--')  # Diagonal line for random classifier\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "478948d6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-09T01:30:22.295373Z",
     "iopub.status.busy": "2024-11-09T01:30:22.294902Z",
     "iopub.status.idle": "2024-11-09T01:30:22.879626Z",
     "shell.execute_reply": "2024-11-09T01:30:22.878476Z"
    },
    "papermill": {
     "duration": 0.666987,
     "end_time": "2024-11-09T01:30:22.882536",
     "exception": false,
     "start_time": "2024-11-09T01:30:22.215549",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# save the oof for inspection\n",
    "oofer = train.loc[:,[target]].copy()\n",
    "oofer[target] = oof\n",
    "oofer.to_csv('oofv1.csv' , index=True)\n",
    "\n",
    "# save the softmaxed oof for inspection\n",
    "oofsmer = train.loc[:,[target]].copy()\n",
    "oofsmer[target] = oofsm\n",
    "oofsmer.to_csv('oofsmv1.csv' , index = True)\n",
    "\n",
    "# build a submission\n",
    "setout = pd.read_csv(\"/kaggle/input/playground-series-s4e10/sample_submission.csv\")\n",
    "setout[target] = outs\n",
    "setout.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a5cc6124",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-09T01:30:23.099698Z",
     "iopub.status.busy": "2024-11-09T01:30:23.099211Z",
     "iopub.status.idle": "2024-11-09T01:30:24.287815Z",
     "shell.execute_reply": "2024-11-09T01:30:24.286390Z"
    },
    "papermill": {
     "duration": 1.328754,
     "end_time": "2024-11-09T01:30:24.291327",
     "exception": false,
     "start_time": "2024-11-09T01:30:22.962573",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id,loan_status\r\n",
      "58645,0.99118894\r\n",
      "58646,0.041345716\r\n",
      "58647,0.2814354\r\n",
      "58648,0.02126211\r\n",
      "58649,0.113522224\r\n",
      "58650,0.9217069\r\n",
      "58651,0.0007730291\r\n",
      "58652,0.013913701\r\n",
      "58653,0.17146665\r\n"
     ]
    }
   ],
   "source": [
    "!head /kaggle/working/submission.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e39bd783",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-09T01:30:24.451432Z",
     "iopub.status.busy": "2024-11-09T01:30:24.450917Z",
     "iopub.status.idle": "2024-11-09T01:30:24.470550Z",
     "shell.execute_reply": "2024-11-09T01:30:24.469206Z"
    },
    "papermill": {
     "duration": 0.102931,
     "end_time": "2024-11-09T01:30:24.473570",
     "exception": false,
     "start_time": "2024-11-09T01:30:24.370639",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "#this is with only one dataset -- obsolete info...\n",
    "from io import StringIO as SO\n",
    "jun = SO('''nnl1,nnl2,nnl3,nnl4,Folds,Epochs,Batch,Steps,LL,LLSM,AUC,LB,LR1,LRM1,LR2,LRM2,LR3,LRM3,ACT,Stops\n",
    "64,128,128,64,12,12,64,840,0.17536744,1.869635836,,,0.004,2,0.001,7,0.0005,5,'relu',6 to 9\n",
    "64,256,256,128,12,12,64,840,0.17542175,1.862260547,.9304,93470,0.004,2,0.001,7,0.0005,5,'relu', 3 to 7 \n",
    "128,256,256,128,12,12,128,420,0.175576069,1.85918751,0.9301,0.93392,0.004,2,0.001,7,0.0005,5,'relu', 3 to 10 \n",
    "128,256,512,128,12,12,128,420,0.178457176,1.919419,0.928,,0.002,2,0.001,9,0.0005,5,'relu', 3 to 10 \n",
    "256,256,256,256,12,12,128,420,0.176362974,1.87824034,0.9301,,0.002,2,0.001,10,,,'relu', 3 to 9 \n",
    "96,192,192,192,12,12,64,840,0.17497970941520888,1.866562798921456,0.9301,,0.004,2,0.001,10,,,'relu', 3 to 9 \n",
    "128,256,256,128,12,12,128,840,0.17953036848404766,1.9077414974817908,0.9302,0.93246,0.003,2,0.002,2,0.001,10,'tanh', 5 to 12 \n",
    "64,128,,128,12,12,128,840,0.1767506723207522,1.875167,0.92946,,0.003,2,0.002,2,0.001,10,'tanh', 5 to 12 \n",
    "256,512,512,256,12,12,128,840,0.18031288003121398,1.9046684602757964,0.9252,,0.003,2,0.002,2,0.001,10,'tanh', 5 to 12 \n",
    "256,512,512,256,12,12,128,840,0.1762869982833868,1.863489,.928328,,0.003,2,0.002,2,0.001,10,'elu', 5 to 12 \n",
    "256,512,512,256,12,30,128,840,0.17300000261123938,1.863489761715461,.933739,,0.002,2,0.001,2,0.0005,22,'elu',  \n",
    "\n",
    "''')\n",
    "ccs = \"nnl1,nnl2,nnl3,nnl4,Folds,Epochs,Batch,Steps,LL,LLSM,AUC,LB,LR1,LRM1,LR2,LRM2,LR3,LRM3,ACT,Stops\".split(',')\n",
    "print(len(ccs))\n",
    "stats = pd.read_csv( jun , sep=\",\")\n",
    "stats.columns = ccs\n",
    "stats.head()\n",
    "stats.to_csv('stats.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b2f129cd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-09T01:30:24.635842Z",
     "iopub.status.busy": "2024-11-09T01:30:24.635293Z",
     "iopub.status.idle": "2024-11-09T01:30:24.668148Z",
     "shell.execute_reply": "2024-11-09T01:30:24.666903Z"
    },
    "papermill": {
     "duration": 0.119026,
     "end_time": "2024-11-09T01:30:24.671126",
     "exception": false,
     "start_time": "2024-11-09T01:30:24.552100",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nnl1</th>\n",
       "      <th>nnl2</th>\n",
       "      <th>nnl3</th>\n",
       "      <th>nnl4</th>\n",
       "      <th>Folds</th>\n",
       "      <th>Epochs</th>\n",
       "      <th>Batch</th>\n",
       "      <th>Steps</th>\n",
       "      <th>LL</th>\n",
       "      <th>LLSM</th>\n",
       "      <th>AUC</th>\n",
       "      <th>LB</th>\n",
       "      <th>LR1</th>\n",
       "      <th>LRM1</th>\n",
       "      <th>LR2</th>\n",
       "      <th>LRM2</th>\n",
       "      <th>LR3</th>\n",
       "      <th>LRM3</th>\n",
       "      <th>ACT</th>\n",
       "      <th>Stops</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>64</td>\n",
       "      <td>128</td>\n",
       "      <td>128.0</td>\n",
       "      <td>64</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>64</td>\n",
       "      <td>840</td>\n",
       "      <td>0.175367</td>\n",
       "      <td>1.869636</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.004</td>\n",
       "      <td>2</td>\n",
       "      <td>0.001</td>\n",
       "      <td>7</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>5.0</td>\n",
       "      <td>'relu'</td>\n",
       "      <td>6 to 9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>64</td>\n",
       "      <td>256</td>\n",
       "      <td>256.0</td>\n",
       "      <td>128</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>64</td>\n",
       "      <td>840</td>\n",
       "      <td>0.175422</td>\n",
       "      <td>1.862261</td>\n",
       "      <td>0.930400</td>\n",
       "      <td>93470.00000</td>\n",
       "      <td>0.004</td>\n",
       "      <td>2</td>\n",
       "      <td>0.001</td>\n",
       "      <td>7</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>5.0</td>\n",
       "      <td>'relu'</td>\n",
       "      <td>3 to 7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>128</td>\n",
       "      <td>256</td>\n",
       "      <td>256.0</td>\n",
       "      <td>128</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>128</td>\n",
       "      <td>420</td>\n",
       "      <td>0.175576</td>\n",
       "      <td>1.859188</td>\n",
       "      <td>0.930100</td>\n",
       "      <td>0.93392</td>\n",
       "      <td>0.004</td>\n",
       "      <td>2</td>\n",
       "      <td>0.001</td>\n",
       "      <td>7</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>5.0</td>\n",
       "      <td>'relu'</td>\n",
       "      <td>3 to 10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>128</td>\n",
       "      <td>256</td>\n",
       "      <td>512.0</td>\n",
       "      <td>128</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>128</td>\n",
       "      <td>420</td>\n",
       "      <td>0.178457</td>\n",
       "      <td>1.919419</td>\n",
       "      <td>0.928000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.002</td>\n",
       "      <td>2</td>\n",
       "      <td>0.001</td>\n",
       "      <td>9</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>5.0</td>\n",
       "      <td>'relu'</td>\n",
       "      <td>3 to 10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>256</td>\n",
       "      <td>256</td>\n",
       "      <td>256.0</td>\n",
       "      <td>256</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>128</td>\n",
       "      <td>420</td>\n",
       "      <td>0.176363</td>\n",
       "      <td>1.878240</td>\n",
       "      <td>0.930100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.002</td>\n",
       "      <td>2</td>\n",
       "      <td>0.001</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>'relu'</td>\n",
       "      <td>3 to 9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>96</td>\n",
       "      <td>192</td>\n",
       "      <td>192.0</td>\n",
       "      <td>192</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>64</td>\n",
       "      <td>840</td>\n",
       "      <td>0.174980</td>\n",
       "      <td>1.866563</td>\n",
       "      <td>0.930100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.004</td>\n",
       "      <td>2</td>\n",
       "      <td>0.001</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>'relu'</td>\n",
       "      <td>3 to 9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>128</td>\n",
       "      <td>256</td>\n",
       "      <td>256.0</td>\n",
       "      <td>128</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>128</td>\n",
       "      <td>840</td>\n",
       "      <td>0.179530</td>\n",
       "      <td>1.907741</td>\n",
       "      <td>0.930200</td>\n",
       "      <td>0.93246</td>\n",
       "      <td>0.003</td>\n",
       "      <td>2</td>\n",
       "      <td>0.002</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>10.0</td>\n",
       "      <td>'tanh'</td>\n",
       "      <td>5 to 12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>64</td>\n",
       "      <td>128</td>\n",
       "      <td>NaN</td>\n",
       "      <td>128</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>128</td>\n",
       "      <td>840</td>\n",
       "      <td>0.176751</td>\n",
       "      <td>1.875167</td>\n",
       "      <td>0.929460</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.003</td>\n",
       "      <td>2</td>\n",
       "      <td>0.002</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>10.0</td>\n",
       "      <td>'tanh'</td>\n",
       "      <td>5 to 12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>256</td>\n",
       "      <td>512</td>\n",
       "      <td>512.0</td>\n",
       "      <td>256</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>128</td>\n",
       "      <td>840</td>\n",
       "      <td>0.180313</td>\n",
       "      <td>1.904668</td>\n",
       "      <td>0.925200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.003</td>\n",
       "      <td>2</td>\n",
       "      <td>0.002</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>10.0</td>\n",
       "      <td>'tanh'</td>\n",
       "      <td>5 to 12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>256</td>\n",
       "      <td>512</td>\n",
       "      <td>512.0</td>\n",
       "      <td>256</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>128</td>\n",
       "      <td>840</td>\n",
       "      <td>0.176287</td>\n",
       "      <td>1.863489</td>\n",
       "      <td>0.928328</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.003</td>\n",
       "      <td>2</td>\n",
       "      <td>0.002</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>10.0</td>\n",
       "      <td>'elu'</td>\n",
       "      <td>5 to 12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>256</td>\n",
       "      <td>512</td>\n",
       "      <td>512.0</td>\n",
       "      <td>256</td>\n",
       "      <td>12</td>\n",
       "      <td>30</td>\n",
       "      <td>128</td>\n",
       "      <td>840</td>\n",
       "      <td>0.173000</td>\n",
       "      <td>1.863490</td>\n",
       "      <td>0.933739</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.002</td>\n",
       "      <td>2</td>\n",
       "      <td>0.001</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>22.0</td>\n",
       "      <td>'elu'</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    nnl1  nnl2   nnl3  nnl4  Folds  Epochs  Batch  Steps        LL      LLSM  \\\n",
       "0     64   128  128.0    64     12      12     64    840  0.175367  1.869636   \n",
       "1     64   256  256.0   128     12      12     64    840  0.175422  1.862261   \n",
       "2    128   256  256.0   128     12      12    128    420  0.175576  1.859188   \n",
       "3    128   256  512.0   128     12      12    128    420  0.178457  1.919419   \n",
       "4    256   256  256.0   256     12      12    128    420  0.176363  1.878240   \n",
       "5     96   192  192.0   192     12      12     64    840  0.174980  1.866563   \n",
       "6    128   256  256.0   128     12      12    128    840  0.179530  1.907741   \n",
       "7     64   128    NaN   128     12      12    128    840  0.176751  1.875167   \n",
       "8    256   512  512.0   256     12      12    128    840  0.180313  1.904668   \n",
       "9    256   512  512.0   256     12      12    128    840  0.176287  1.863489   \n",
       "10   256   512  512.0   256     12      30    128    840  0.173000  1.863490   \n",
       "\n",
       "         AUC           LB    LR1  LRM1    LR2  LRM2     LR3  LRM3     ACT  \\\n",
       "0        NaN          NaN  0.004     2  0.001     7  0.0005   5.0  'relu'   \n",
       "1   0.930400  93470.00000  0.004     2  0.001     7  0.0005   5.0  'relu'   \n",
       "2   0.930100      0.93392  0.004     2  0.001     7  0.0005   5.0  'relu'   \n",
       "3   0.928000          NaN  0.002     2  0.001     9  0.0005   5.0  'relu'   \n",
       "4   0.930100          NaN  0.002     2  0.001    10     NaN   NaN  'relu'   \n",
       "5   0.930100          NaN  0.004     2  0.001    10     NaN   NaN  'relu'   \n",
       "6   0.930200      0.93246  0.003     2  0.002     2  0.0010  10.0  'tanh'   \n",
       "7   0.929460          NaN  0.003     2  0.002     2  0.0010  10.0  'tanh'   \n",
       "8   0.925200          NaN  0.003     2  0.002     2  0.0010  10.0  'tanh'   \n",
       "9   0.928328          NaN  0.003     2  0.002     2  0.0010  10.0   'elu'   \n",
       "10  0.933739          NaN  0.002     2  0.001     2  0.0005  22.0   'elu'   \n",
       "\n",
       "        Stops  \n",
       "0      6 to 9  \n",
       "1     3 to 7   \n",
       "2    3 to 10   \n",
       "3    3 to 10   \n",
       "4     3 to 9   \n",
       "5     3 to 9   \n",
       "6    5 to 12   \n",
       "7    5 to 12   \n",
       "8    5 to 12   \n",
       "9    5 to 12   \n",
       "10             "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "252bde8c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-09T01:30:24.833731Z",
     "iopub.status.busy": "2024-11-09T01:30:24.833256Z",
     "iopub.status.idle": "2024-11-09T01:30:24.838496Z",
     "shell.execute_reply": "2024-11-09T01:30:24.837236Z"
    },
    "papermill": {
     "duration": 0.089359,
     "end_time": "2024-11-09T01:30:24.841141",
     "exception": false,
     "start_time": "2024-11-09T01:30:24.751782",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# stas = pd.read_csv('/kaggle/working/stats.csv')\n",
    "# stats.to_clipboard()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "04efc8dd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-09T01:30:24.999680Z",
     "iopub.status.busy": "2024-11-09T01:30:24.999206Z",
     "iopub.status.idle": "2024-11-09T01:30:26.172941Z",
     "shell.execute_reply": "2024-11-09T01:30:26.171640Z"
    },
    "papermill": {
     "duration": 1.256443,
     "end_time": "2024-11-09T01:30:26.176025",
     "exception": false,
     "start_time": "2024-11-09T01:30:24.919582",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id,loan_status\r\n",
      "58645,0.99118894\r\n",
      "58646,0.041345716\r\n",
      "58647,0.2814354\r\n",
      "58648,0.02126211\r\n",
      "58649,0.113522224\r\n",
      "58650,0.9217069\r\n",
      "58651,0.0007730291\r\n",
      "58652,0.013913701\r\n",
      "58653,0.17146665\r\n"
     ]
    }
   ],
   "source": [
    "!head /kaggle/working/submission.csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f95de05e",
   "metadata": {
    "papermill": {
     "duration": 0.079951,
     "end_time": "2024-11-09T01:30:26.334795",
     "exception": false,
     "start_time": "2024-11-09T01:30:26.254844",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 9709193,
     "sourceId": 84894,
     "sourceType": "competition"
    },
    {
     "datasetId": 4675026,
     "sourceId": 7949759,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30775,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1568.428909,
   "end_time": "2024-11-09T01:30:29.170104",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-11-09T01:04:20.741195",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
